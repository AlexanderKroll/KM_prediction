{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "Four Jupyter notebookes with code to reproduce the results and plots of the paper \"Prediction of Michaelis constants $K_M$ from structural features\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python 3\n",
    "- tesnsorlow\n",
    "- jupyter\n",
    "- pandas\n",
    "- scikit-learn\n",
    "- rdkit\n",
    "- zeep\n",
    "- matplotlib\n",
    "- py-xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The listed packaged can be installed using conda and anaconda:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "conda install -c anaconda tensorflow\n",
    "conda install -c anaconda jupyter\n",
    "conda install -c anaconda pandas\n",
    "conda install -c anaconda scikit-learn\n",
    "conda install -c rdkit rdkit\n",
    "conda install -c conda-forge zeep\n",
    "conda install -c conda-forge matplotlib\n",
    "conda install -c conda-forge py-xgboost\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exist four different jupyter notebooks in the folder named \"code\".  All machine learning models in these jupyter notebooks can be either trained or our pretrained weights can be loaded from the folder \"datasets/model_weights\".\n",
    "\n",
    "#### - Downloading and preprocessing BRENDA data.ipynb:\n",
    "Conatins all the necessary steps to download the data from BRENDA, to preprocess it and to split it into training, test, and validation set. Alternatively to executing the code in this notebook, our training, test, and validation sets (named \"test_data.pkl\", \"training_data.pkl\", and \"validation_data.pkl\"), which are stored in the folder named datasets, can be used for model training and evaluation.\n",
    "\n",
    "#### - Training full model with enzyme and substrate information.ipynb:\n",
    "Contains all steps to train and validate our final model that uses enzyme and substrate information to predict KM values. It also contains the code to plot figure 4 of our paper.\n",
    "\n",
    "#### - Effect of additional features (MW and LogP) for the GNN.ipynb:\n",
    "To investigate the effect of the two additional features, molecular weight and LogP-coefficient, for the performance of the GNN, we trained and validated models with both, with only one, and with none of these features and compare the results. It also contains the code to plot figure 3 of our paper.\n",
    "\n",
    "#### - Training FCNN with ECFPs.ipynb:\n",
    "Contains the training of a fully-connected neural network (FCNN) with extended-connectivity fingerprints (ECFPs) as input and the code to plot figure 2 of our paper."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
