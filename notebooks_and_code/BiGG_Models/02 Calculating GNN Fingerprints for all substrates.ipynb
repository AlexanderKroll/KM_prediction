{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import xgboost as xgb\n",
    "from tensorflow.keras import backend as K\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from directory_infomation import *\n",
    "from functions_and_dicts_data_preprocessing_GNN import *\n",
    "from build_GNN import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model with trained parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<__main__.Linear_with_bias object at 0x0000024E13186588> and <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x0000024E0CBF7688>).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x24e13801648>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model parameters\n",
    "N = 70        # maximum number of nodes\n",
    "F1 = 32         # feature dimensionality of atoms\n",
    "F2 = 10         # feature dimensionality of bonds\n",
    "F = F1+F2\n",
    "\n",
    "class Linear(layers.Layer):\n",
    "\n",
    "    def __init__(self, dim=(1,1,42,64)):\n",
    "        super(Linear, self).__init__()\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(initial_value = w_init(shape=(dim),\n",
    "                                                  dtype='float32'),\n",
    "                             trainable=True)\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w)\n",
    "    \n",
    "    \n",
    "class Linear_with_bias(layers.Layer):\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        super(Linear_with_bias, self).__init__()\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        b_init = tf.constant_initializer(0.1)\n",
    "        self.w = tf.Variable(initial_value = w_init(shape=(dim),\n",
    "                                                  dtype='float32'),\n",
    "                             trainable=True)\n",
    "        self.b = tf.Variable(initial_value = b_init(shape=[self.w.shape[-1]], dtype='float32'), trainable=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.math.add(tf.matmul(inputs, self.w), self.b)\n",
    "\n",
    "\n",
    "def DMPNN(l2_reg_conv, l2_reg_fc, learning_rate, D, N, F1, F2, F, drop_rate = 0.15, ada_rho = 0.95):\n",
    "\n",
    "    # Model definition\n",
    "    XE_in = Input(shape=(N, N, F), name = \"XE\", dtype='float32')\n",
    "    X_in = Input(shape=(N, F1), dtype='float32')\n",
    "    Extras_in = Input((2), name =\"Extras\", dtype='float32')\n",
    "    Unirep_in = Input((20), name =\"Unirep\", dtype='float32')\n",
    "\n",
    "    X = tf.reshape(X_in, (-1, N, 1, F1))\n",
    "    A_in = Input((N, N, 1),name =\"A\", dtype='float32') # 64 copies of A stacked behind each other\n",
    "    Wi = Linear((1,1,F,D))\n",
    "    Wm1 = Linear((1,1,D,D))\n",
    "    Wm2= Linear((1,1,D,D))\n",
    "    Wa = Linear((1,D+F1,D))\n",
    "\n",
    "    W_fc1 = Linear_with_bias([D + 2, 32])\n",
    "    W_fc2 = Linear_with_bias([32, 16])\n",
    "    W_fc3=  Linear_with_bias([16, 1])\n",
    "\n",
    "    OnesN_N = tf.ones((N,N))\n",
    "    Ones1_N = tf.ones((1,N))\n",
    "\n",
    "    H0 = relu(Wi(XE_in)) #W*XE\n",
    "\n",
    "    #only get neighbors in each row: (elementwise multiplication)\n",
    "    M1 = tf.multiply(H0, A_in)\n",
    "    M1 = tf.transpose(M1, perm =[0,2,1,3])\n",
    "    M1 = tf.matmul(OnesN_N, M1)\n",
    "    M1 = add(inputs= [M1,-tf.transpose(H0, perm =[0,2,1,3])])\n",
    "    M1 = tf.multiply(M1, A_in)\n",
    "    H1 = add(inputs = [H0, Wm1(M1)])\n",
    "    H1 = relu(BatchNormalization(momentum=0.90, trainable=True)(H1))\n",
    "\n",
    "    M2 = tf.multiply(H1, A_in)\n",
    "    M2 = tf.transpose(M2, perm =[0,2,1,3])\n",
    "    M2 = tf.matmul(OnesN_N, M2)\n",
    "    M2 = add(inputs= [M2,-tf.transpose(H1, perm =[0,2,1,3])])\n",
    "    M2 = tf.multiply(M2, A_in)\n",
    "    H2 = add(inputs = [H0, Wm2(M2)]) \n",
    "    H2 = relu(BatchNormalization(momentum=0.90, trainable=True)(H2))\n",
    "    \n",
    "    M_v = tf.multiply(H2, A_in)\n",
    "    M_v = tf.matmul(Ones1_N, M_v)\n",
    "    XM = Concatenate()(inputs= [X, M_v])\n",
    "    H = relu(Wa(XM))\n",
    "    h = tf.matmul(Ones1_N, tf.transpose(H, perm= [0,2,1,3]))\n",
    "    h = tf.reshape(h, (-1,D))\n",
    "    h_extras = Concatenate()(inputs= [h, Extras_in])\n",
    "    h_extras = BatchNormalization(momentum=0.90, trainable=True)(h_extras)\n",
    "\n",
    "    fc1 = relu(W_fc1(h_extras))\n",
    "    fc1 = BatchNormalization(momentum=0.90, trainable=True)(fc1)\n",
    "    fc1 = Dropout(drop_rate)(fc1)\n",
    "\n",
    "    fc2 =relu(W_fc2(fc1))\n",
    "    fc2 = BatchNormalization(momentum=0.90, trainable=True)(fc2)\n",
    "\n",
    "    output = W_fc3(fc2)\n",
    "    \n",
    "    def total_loss(y_true, y_pred):\n",
    "        reg_conv_loss = (tf.nn.l2_loss(Wi.w) + tf.nn.l2_loss(Wm1.w)+ tf.nn.l2_loss(Wm2.w) + tf.nn.l2_loss(Wa.w))\n",
    "        reg_fc_loss = (tf.nn.l2_loss(W_fc1.w) +tf.nn.l2_loss(W_fc2.w) +tf.nn.l2_loss(W_fc3.w))\n",
    "        mse_loss = tf.keras.losses.MSE(y_true, y_pred)\n",
    "        return(tf.reduce_mean(mse_loss + l2_reg_conv * reg_conv_loss + l2_reg_fc * reg_fc_loss))\n",
    "\n",
    "    # Build model\n",
    "    model = Model(inputs=[XE_in, X_in, A_in, Extras_in, Unirep_in], outputs=output)\n",
    "\n",
    "    #tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, H1_batch.updates)\n",
    "    optimizer = Adadelta(lr=learning_rate, rho = ada_rho)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=total_loss, metrics=['mse', \"mae\"])\n",
    "    return(model)\n",
    "\n",
    "\n",
    "batch_size =32\n",
    "D = 50\n",
    "learning_rate = 0.05\n",
    "epochs = 50\n",
    "l2_reg_fc = 0.01\n",
    "l2_reg_conv = 0.01\n",
    "rho = 0.99 \n",
    "\n",
    "\n",
    "model = DMPNN(l2_reg_conv = l2_reg_conv, l2_reg_fc = l2_reg_fc, learning_rate = learning_rate,\n",
    "                  D = D, N = N, F1 = F1, F2 = F2, F= F, drop_rate = 0.0, ada_rho = rho)\n",
    "model.load_weights(join(datasets_dir, \"model_weights\", \"saved_model_GNN_best_hyperparameters\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new model which can process molecules with up to 250 atoms (instead of just 70) and use the learned weights from the model above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "N = 100        # maximum number of nodes\n",
    "F1 = 32         # feature dimensionality of atoms\n",
    "F2 = 10         # feature dimensionality of bonds\n",
    "F = F1+F2\n",
    "\n",
    "class Linear(layers.Layer):\n",
    "\n",
    "    def __init__(self, dim=(1,1,42,64)):\n",
    "        super(Linear, self).__init__()\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(initial_value = w_init(shape=(dim),\n",
    "                                                  dtype='float32'),\n",
    "                             trainable=True)\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w)\n",
    "    \n",
    "    \n",
    "class Linear_with_bias(layers.Layer):\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        super(Linear_with_bias, self).__init__()\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        b_init = tf.constant_initializer(0.1)\n",
    "        self.w = tf.Variable(initial_value = w_init(shape=(dim),\n",
    "                                                  dtype='float32'),\n",
    "                             trainable=True)\n",
    "        self.b = tf.Variable(initial_value = b_init(shape=[self.w.shape[-1]], dtype='float32'), trainable=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.math.add(tf.matmul(inputs, self.w), self.b)\n",
    "\n",
    "\n",
    "def DMPNN(l2_reg_conv, l2_reg_fc, learning_rate, D, N, F1, F2, F, drop_rate = 0.15, ada_rho = 0.95):\n",
    "\n",
    "    # Model definition\n",
    "    XE_in = Input(shape=(N, N, F), name = \"XE\", dtype='float32')\n",
    "    X_in = Input(shape=(N, F1), dtype='float32')\n",
    "    Extras_in = Input((2), name =\"Extras\", dtype='float32')\n",
    "    Unirep_in = Input((20), name =\"Unirep\", dtype='float32')\n",
    "\n",
    "    X = tf.reshape(X_in, (-1, N, 1, F1))\n",
    "    A_in = Input((N, N, 1),name =\"A\", dtype='float32') # 64 copies of A stacked behind each other\n",
    "    Wi = Linear((1,1,F,D))\n",
    "    Wm1 = Linear((1,1,D,D))\n",
    "    Wm2= Linear((1,1,D,D))\n",
    "    Wa = Linear((1,D+F1,D))\n",
    "\n",
    "    W_fc1 = Linear_with_bias([D + 2, 32])\n",
    "    W_fc2 = Linear_with_bias([32, 16])\n",
    "    W_fc3=  Linear_with_bias([16, 1])\n",
    "\n",
    "    OnesN_N = tf.ones((N,N))\n",
    "    Ones1_N = tf.ones((1,N))\n",
    "\n",
    "    H0 = relu(Wi(XE_in)) #W*XE\n",
    "\n",
    "    #only get neighbors in each row: (elementwise multiplication)\n",
    "    M1 = tf.multiply(H0, A_in)\n",
    "    M1 = tf.transpose(M1, perm =[0,2,1,3])\n",
    "    M1 = tf.matmul(OnesN_N, M1)\n",
    "    M1 = add(inputs= [M1,-tf.transpose(H0, perm =[0,2,1,3])])\n",
    "    M1 = tf.multiply(M1, A_in)\n",
    "    H1 = add(inputs = [H0, Wm1(M1)])\n",
    "    H1 = relu(BatchNormalization(momentum=0.90, trainable=True)(H1))\n",
    "\n",
    "    M2 = tf.multiply(H1, A_in)\n",
    "    M2 = tf.transpose(M2, perm =[0,2,1,3])\n",
    "    M2 = tf.matmul(OnesN_N, M2)\n",
    "    M2 = add(inputs= [M2,-tf.transpose(H1, perm =[0,2,1,3])])\n",
    "    M2 = tf.multiply(M2, A_in)\n",
    "    H2 = add(inputs = [H0, Wm2(M2)]) \n",
    "    H2 = relu(BatchNormalization(momentum=0.90, trainable=True)(H2))\n",
    "    \n",
    "    M_v = tf.multiply(H2, A_in)\n",
    "    M_v = tf.matmul(Ones1_N, M_v)\n",
    "    XM = Concatenate()(inputs= [X, M_v])\n",
    "    H = relu(Wa(XM))\n",
    "    h = tf.matmul(Ones1_N, tf.transpose(H, perm= [0,2,1,3]))\n",
    "    h = tf.reshape(h, (-1,D))\n",
    "    h_extras = Concatenate()(inputs= [h, Extras_in])\n",
    "    h_extras = BatchNormalization(momentum=0.90, trainable=True)(h_extras)\n",
    "\n",
    "    fc1 = relu(W_fc1(h_extras))\n",
    "    fc1 = BatchNormalization(momentum=0.90, trainable=True)(fc1)\n",
    "    fc1 = Dropout(drop_rate)(fc1)\n",
    "\n",
    "    fc2 =relu(W_fc2(fc1))\n",
    "    fc2 = BatchNormalization(momentum=0.90, trainable=True)(fc2)\n",
    "\n",
    "    output = W_fc3(fc2)\n",
    "    \n",
    "    def total_loss(y_true, y_pred):\n",
    "        reg_conv_loss = (tf.nn.l2_loss(Wi.w) + tf.nn.l2_loss(Wm1.w)+ tf.nn.l2_loss(Wm2.w) + tf.nn.l2_loss(Wa.w))\n",
    "        reg_fc_loss = (tf.nn.l2_loss(W_fc1.w) +tf.nn.l2_loss(W_fc2.w) +tf.nn.l2_loss(W_fc3.w))\n",
    "        mse_loss = tf.keras.losses.MSE(y_true, y_pred)\n",
    "        return(tf.reduce_mean(mse_loss + l2_reg_conv * reg_conv_loss + l2_reg_fc * reg_fc_loss))\n",
    "\n",
    "    # Build model\n",
    "    model = Model(inputs=[XE_in, X_in, A_in, Extras_in, Unirep_in], outputs=output)\n",
    "\n",
    "    #tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, H1_batch.updates)\n",
    "    optimizer = Adadelta(lr=learning_rate, rho = ada_rho)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=total_loss, metrics=['mse', \"mae\"])\n",
    "    return(model)\n",
    "\n",
    "\n",
    "model_250 = DMPNN(l2_reg_conv = l2_reg_conv, l2_reg_fc = l2_reg_fc, learning_rate = learning_rate,\n",
    "                  D = D, N = 250, F1 = F1, F2 = F2, F= F, drop_rate = 0.0, ada_rho = rho)\n",
    "model_250.set_weights = model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating fingerprints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metanetx ID</th>\n",
       "      <th>KEGG ID</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>substrate_available</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MNXM3</td>\n",
       "      <td>C00002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MNXM89621</td>\n",
       "      <td>C05345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MNXM12</td>\n",
       "      <td>C00010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNXM23</td>\n",
       "      <td>C00022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MNXM160</td>\n",
       "      <td>C00092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4451</th>\n",
       "      <td>NaN</td>\n",
       "      <td>C00479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4452</th>\n",
       "      <td>NaN</td>\n",
       "      <td>C00163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>NaN</td>\n",
       "      <td>C00100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>NaN</td>\n",
       "      <td>C06044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>NaN</td>\n",
       "      <td>C05979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4456 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     metanetx ID KEGG ID SMILES  substrate_available\n",
       "0          MNXM3  C00002    NaN                 True\n",
       "1      MNXM89621  C05345    NaN                 True\n",
       "2         MNXM12  C00010    NaN                 True\n",
       "3         MNXM23  C00022    NaN                 True\n",
       "4        MNXM160  C00092    NaN                 True\n",
       "...          ...     ...    ...                  ...\n",
       "4451         NaN  C00479    NaN                False\n",
       "4452         NaN  C00163    NaN                False\n",
       "4453         NaN  C00100    NaN                False\n",
       "4454         NaN  C06044    NaN                False\n",
       "4455         NaN  C05979    NaN                False\n",
       "\n",
       "[4456 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subs = pd.read_pickle(join(datasets_dir, \"BiGG_data\", \"df_subs.pkl\"))\n",
    "df_subs_avail = df_subs.loc[df_subs[\"substrate_available\"] == True]\n",
    "df_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_fingerprint_fct = K.function([[model_250.layers[0].input, model_250.layers[26].input,\n",
    "                                  model_250.layers[3].input, model_250.layers[36].input]],\n",
    "                                  [model_250.layers[-10].output])\n",
    "\n",
    "def get_substrate_representations(df):\n",
    "    df[\"GNN FP\"] = \"\"\n",
    "    i = 0\n",
    "    n = len(df)\n",
    "    UniRep = np.zeros((64, 20))\n",
    "    cid_all = list(df[\"metanetx ID\"])\n",
    "    \n",
    "    while i*64 <= n:\n",
    "        if (i+1)*64  <= n:\n",
    "            XE, X, A, extras = get_representation_input(cid_all[i*64:(i+1)*64])\n",
    "            representations = get_fingerprint_fct([np.array(XE), np.array(X),np.array(A),\n",
    "                                                   np.array(extras)])[0]\n",
    "            df[\"GNN FP\"][i*64:(i+1)*64] = list(representations[:, :52])\n",
    "        else:\n",
    "            print(i)\n",
    "            XE, X, A, extras = get_representation_input(cid_all[-64:])\n",
    "            representations = get_fingerprint_fct([np.array(XE), np.array(X),np.array(A),\n",
    "                                                   np.array(extras)])[0]\n",
    "            df[\"GNN FP\"][-64:] = list(representations[:, :52])\n",
    "        i += 1\n",
    "        \n",
    "    return(df)\n",
    "\n",
    "input_data_folder = join(datasets_dir, \"Bigg_data\", \"input_data\")        \n",
    "def get_representation_input(cid_list):\n",
    "    XE = ();\n",
    "    X = ();\n",
    "    A = ();\n",
    "    UniRep = ();\n",
    "    extras = ();\n",
    "    # Generate data\n",
    "    for cid in cid_list:\n",
    "        X = X + (np.load(join(input_data_folder, cid + '_X.npy')), );\n",
    "        XE = XE + (np.load(join(input_data_folder, cid + '_XE.npy')), );\n",
    "        A = A + (np.load(join(input_data_folder, cid + '_A.npy')), );\n",
    "        extras =  extras + (np.load(join(input_data_folder, cid + '_extras.npy')), );\n",
    "    return(XE, X, A, extras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "df_subs_avail = get_substrate_representations(df = df_subs_avail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge df_subs and df_subs_avail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metanetx ID</th>\n",
       "      <th>KEGG ID</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>substrate_available</th>\n",
       "      <th>GNN FP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MNXM3</td>\n",
       "      <td>C00002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>[3.5004892, 0.0, 0.42342216, 0.023474924, 0.26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MNXM89621</td>\n",
       "      <td>C05345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>[1.8386872, 0.0, 0.0, 0.007824975, 0.0, 1.4801...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MNXM12</td>\n",
       "      <td>C00010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>[4.6419253, 0.0, 0.42342216, 0.039124876, 0.27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNXM23</td>\n",
       "      <td>C00022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.5204832, 0.0, 0.0, 0.01564995, 0.0, 0.22595...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MNXM160</td>\n",
       "      <td>C00092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>[1.9818256, 0.0, 0.0, 0.007824975, 0.0, 1.2651...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624789</th>\n",
       "      <td>NaN</td>\n",
       "      <td>C00479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624790</th>\n",
       "      <td>NaN</td>\n",
       "      <td>C00163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624791</th>\n",
       "      <td>NaN</td>\n",
       "      <td>C00100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624792</th>\n",
       "      <td>NaN</td>\n",
       "      <td>C06044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624793</th>\n",
       "      <td>NaN</td>\n",
       "      <td>C05979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624794 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       metanetx ID KEGG ID SMILES  substrate_available  \\\n",
       "0            MNXM3  C00002    NaN                 True   \n",
       "1        MNXM89621  C05345    NaN                 True   \n",
       "2           MNXM12  C00010    NaN                 True   \n",
       "3           MNXM23  C00022    NaN                 True   \n",
       "4          MNXM160  C00092    NaN                 True   \n",
       "...            ...     ...    ...                  ...   \n",
       "624789         NaN  C00479    NaN                False   \n",
       "624790         NaN  C00163    NaN                False   \n",
       "624791         NaN  C00100    NaN                False   \n",
       "624792         NaN  C06044    NaN                False   \n",
       "624793         NaN  C05979    NaN                False   \n",
       "\n",
       "                                                   GNN FP  \n",
       "0       [3.5004892, 0.0, 0.42342216, 0.023474924, 0.26...  \n",
       "1       [1.8386872, 0.0, 0.0, 0.007824975, 0.0, 1.4801...  \n",
       "2       [4.6419253, 0.0, 0.42342216, 0.039124876, 0.27...  \n",
       "3       [0.5204832, 0.0, 0.0, 0.01564995, 0.0, 0.22595...  \n",
       "4       [1.9818256, 0.0, 0.0, 0.007824975, 0.0, 1.2651...  \n",
       "...                                                   ...  \n",
       "624789                                                NaN  \n",
       "624790                                                NaN  \n",
       "624791                                                NaN  \n",
       "624792                                                NaN  \n",
       "624793                                                NaN  \n",
       "\n",
       "[624794 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subs_avail = df_subs_avail.drop(columns = [\"SMILES\", \"KEGG ID\", \"substrate_available\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subs_avail.to_pickle(join(datasets_dir, \"BiGG_data\", \"df_subs_avail.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
